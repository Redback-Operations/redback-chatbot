{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions for Setting Up the Environment:\n",
    "1. If this is a new instance:\n",
    "   - Create a new virtual Python environment to ensure a clean, isolated environment for your project dependencies. You can create a new virtual environment using  your IDE or directly from your terminal.\n",
    "   - Ensure that Jupyter Notebook is installed in that environment, and then launch it.\n",
    "   - Confirm that the correct environment is selected as the kernel.\n",
    "2. If an existing environment is available:\n",
    "   - Activate the existing virtual environment where you want to run this notebook.\n",
    "   - Ensure that Jupyter Notebook is installed in that environment, and then launch it.\n",
    "   - Confirm that the correct environment is selected as the kernel.\n",
    "3. Install Required Dependencies:\n",
    "   - Once you have the correct environment set as the kernel, use the `%pip` magic command in a new notebook cell to install the required dependencies.\n",
    "   - This command will ensure all the necessary libraries are installed in the environment associated with the notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Library Imports\n",
    "Built-in libraries in Python that provide functionalities such as file handling, working with paths, and generating unique identifiers.\n",
    "\n",
    "#### Third-Party Imports\n",
    "External libraries installed previously (requirements.txt) for specialised use in this project.\n",
    "\n",
    "- pymupdf4llm: A library for processing PDF files.\n",
    "- SentenceTransformer: A framework for sentence embedding using state-of-the-art models.\n",
    "- QdrantClient: A client library for interacting with Qdrant, a vector search engine.\n",
    "- Flashrank: A library for ranking search results\n",
    "- ChatGroq: A library for integrating Groq-based models with LangChain.\n",
    "- PromptTemplate: A utility from LangChain for creating customisable prompts.\n",
    "- ConversationBufferMemory: A memory buffer module from LangChain for handling conversations.\n",
    "- MarkdownTextSplitter: A tool from LangChain for splitting text into Markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import pathlib\n",
    "import uuid\n",
    "\n",
    "# Third-party imports\n",
    "import pymupdf4llm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from flashrank import Ranker, RerankRequest\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.memory.buffer import ConversationBufferMemory\n",
    "from langchain.text_splitter import MarkdownTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting PDF Files to Markdown\n",
    "\n",
    "The function is used to convert all PDF files located in the `docs` folder into Markdown format. The converted files are then saved in the `parsed_docs` folder.\n",
    "\n",
    "By iterating over all the files in the `docs` folder, the function checks for files with a `.pdf` extension, converts them to Markdown, and saves them with an uppercase file name in the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing docs\\fed_gov_guide.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/18=[====                                    ] ( 2/18=[======                                  ] ( 3/18=[========                                ] ( 4/18==[===========                             ] ( 5/1=[=============                           ] ( 6/1=[===============                         ] ( 7/1=[=================                       ] ( 8/1==[====================                    ] ( 9/18=[======================                  ] (10/18=[========================                ] (11/18=[==========================              ] (12/18=[============================            ] (13/18==[===============================         ] (14/1=[=================================       ] (15/1=[===================================     ] (16/1=[=====================================   ] (17/1==[========================================] (18/18]\n"
     ]
    }
   ],
   "source": [
    "def convert_pdf_to_text(pdf_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts a PDF file to Markdown text and saves it to a specified\n",
    "    output folder with the file name fully capitalised.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the input PDF file.\n",
    "        output_folder (str): The folder where the converted Markdown\n",
    "                             file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value. It saves the\n",
    "              converted text as a Markdown (.md) file in the specified\n",
    "              output folder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the PDF to Markdown\n",
    "    import_doc = pymupdf4llm.to_markdown(pdf_path)\n",
    "\n",
    "    # Get the base name of the file, capitalise it, and replace extension\n",
    "    base_name = os.path.basename(pdf_path).replace('.pdf', '').upper()\n",
    "    output_file = os.path.join(output_folder, f\"{base_name}.md\")\n",
    "\n",
    "    # Save the converted document to the specified output file\n",
    "    pathlib.Path(output_file).write_bytes(import_doc.encode())\n",
    "\n",
    "# Convert all PDFs in the /documents folder\n",
    "for pdf_file in os.listdir('docs'):\n",
    "    if pdf_file.endswith('.pdf'):\n",
    "        convert_pdf_to_text(os.path.join('docs', pdf_file), 'parsed_docs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Path and Listing Markdown Files\n",
    "\n",
    "This section sets the path to the directory containing parsed Markdown files and lists all Markdown files within it.\n",
    "\n",
    "- `notebook_path`: Gets the current directory.\n",
    "- `docs_path`: Path to `parsed_docs` where Markdown files are stored.\n",
    "- `documents`: List of full paths to all `.md` files in `parsed_docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing parsed Markdown files\n",
    "notebook_path = os.getcwd()\n",
    "docs_path = os.path.join(notebook_path, 'parsed_docs')\n",
    "\n",
    "# List all Markdown files in the directory\n",
    "documents = [\n",
    "    os.path.join(docs_path, file)\n",
    "    for file in os.listdir(docs_path)\n",
    "    if file.endswith('.md')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Markdown Files into Chunks\n",
    "\n",
    "This section initialises a text splitter to divide the Markdown files into smaller chunks for easier processing.\n",
    "\n",
    "- `text_splitter`: Initialises a splitter to divide text into chunks of 500 characters with a 50-character overlap.\n",
    "- `chunks`: A list containing all chunks extracted from the Markdown files.\n",
    "- Output Check: Prints the total number of chunks and displays the first chunk to verify the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "['# Choose Health:\\n Be Active\\n\\n\\n##### A physical activity guide for older Australians\\n\\n###### An initiative of the Australian Government in\\n\\n association with Sports Medicine Australia\\n\\n\\n-----\\n\\n**Choose Health: Be Active**\\n\\nFirst printed April 2005\\nRevised and reprinted April 2008\\nRevised and reprinted June 2008\\nISBN 978-1-920720-2856']\n"
     ]
    }
   ],
   "source": [
    "# Initialise the text splitter\n",
    "text_splitter = MarkdownTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# Split all documents into chunks\n",
    "chunks = []\n",
    "for doc in documents:\n",
    "    with open(doc, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        chunk = text_splitter.split_text(text)\n",
    "        chunks.extend(chunk)\n",
    "\n",
    "# Check: Print the number of chunks and the first chunk\n",
    "print(len(chunks))\n",
    "print(chunks[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising the Sentence Encoder\n",
    "\n",
    "We initialise a sentence encoder model to generate embeddings for the text chunks.\n",
    "\n",
    "- `encoder`: A `SentenceTransformer` model (`all-MiniLM-L6-v2`) is used for generating text embeddings to represent the meaning of sentences or chunks.\n",
    "\n",
    "`all-MiniLM-L6-v2` model is an lightweight and efficient open-source transformer model fine-tuned for various sentence embedding tasks. It provides a good balance between speed and accuracy, making it suitable for applications like semantic search, clustering, and text classification. Despite its smaller size, it performs well across multiple languages and contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Embeddings for Text Chunks\n",
    "\n",
    "In this step, we use the initialised sentence encoder to generate embeddings for the text chunks. These embeddings are numerical representations of the text, capturing their semantic meaning.\n",
    "\n",
    "- `embeddings`: A list of vectors generated by the `encoder` for each chunk of text. These embeddings can be used for various downstream tasks, such as similarity search, clustering, or classification, where the semantic content of the text is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.encode(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data for Upload with Unique Identifiers\n",
    "\n",
    "In this section, we generate unique IDs for each text chunk and prepare the data for uploading to a vector database.\n",
    "\n",
    "- `ids`: A list of unique identifiers generated for each text chunk using UUIDs.\n",
    "- `points`: A list of `PointStruct` objects, each containing:\n",
    "  - `id`: A unique identifier for the chunk.\n",
    "  - `vector`: The embedding representing the chunk's semantic content.\n",
    "  - `payload`: An optional dictionary with the original text, useful for retrieval tasks or additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique IDs\n",
    "ids = [str(uuid.uuid4()) for _ in range(len(chunks))]\n",
    "\n",
    "# Prepare data for upload\n",
    "points = [\n",
    "    PointStruct(\n",
    "        id=id,\n",
    "        vector=embedding,\n",
    "        payload={\"text\": chunk}  # Optional payload with original text\n",
    "    )\n",
    "    for id, embedding, chunk in zip(ids, embeddings, chunks)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying Prepared Data Points\n",
    "\n",
    "This step checks the structure and content of the prepared data points by printing the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PointStruct(id='e83b6727-c040-47d3-b165-a47db5f356bb', vector=[0.09132414311170578, 0.003608893370255828, 0.00802591722458601, 0.09255637228488922, -0.0016212842892855406, 0.10537403076887131, 0.07642673701047897, -0.00259967939928174, -0.06672266870737076, 0.12426268309354782, 0.020014192909002304, 1.565547972859349e-05, -0.041562583297491074, 0.03374786674976349, 0.12447652220726013, 0.04611389711499214, -0.012749030254781246, -0.04728269949555397, -0.0045511312782764435, 0.04754595831036568, -0.046240612864494324, 0.11829520016908646, 0.048751913011074066, 0.04791689291596413, -0.034289389848709106, 0.01574784144759178, -0.012838504277169704, 0.005514912307262421, -0.04133659601211548, 0.028025276958942413, 0.005489352159202099, 0.04444870352745056, 0.06721746921539307, -0.006648452952504158, 0.0006244006799533963, -0.052473317831754684, -0.02547653391957283, -0.044095054268836975, -0.12334436923265457, -0.011725603602826595, 0.0466545931994915, -0.08336395770311356, 0.009355216287076473, 0.0047754039987921715, -0.04073057323694229, 0.009780279360711575, -0.026057163253426552, -0.0037593571469187737, 0.03886394947767258, 0.0961102843284607, -0.03162383288145065, -0.04089033976197243, 0.06526481360197067, -0.06502225250005722, 0.09090624749660492, -0.05026889219880104, -0.03945564851164818, -0.07839518040418625, -0.08931206911802292, -0.05829107016324997, 0.023146996274590492, -0.00606454536318779, -0.03708844631910324, 0.006986904423683882, -0.0668717697262764, -0.013795359991490841, -0.05168890580534935, 0.005784821696579456, 0.05471065640449524, -0.04496021568775177, -0.10836426913738251, -0.02188032679259777, 0.03182985633611679, 0.026677105575799942, 0.01131604053080082, -0.035935018211603165, 0.016105467453598976, -0.07237277179956436, 0.03394607827067375, -0.03380730748176575, -0.06059698015451431, -0.0390617661178112, -0.01638270542025566, 0.03792291879653931, 0.03732336312532425, 0.009404611773788929, 0.0397847481071949, 0.009086568839848042, -0.009443684481084347, -0.03781432285904884, -0.10167260468006134, 0.05629487335681915, 0.038169633597135544, 0.026127731427550316, 0.008619997650384903, -0.01857132650911808, -0.12289625406265259, -0.038444142788648605, -0.08730439841747284, 0.030176136642694473, 0.02558395266532898, -0.03231142461299896, 0.019895583391189575, 0.1441555917263031, -0.10574666410684586, -0.07810678333044052, -0.06955919414758682, 0.033733200281858444, 0.11122707277536392, 0.09854785352945328, 0.018867818638682365, -0.00907179992645979, 0.05514897033572197, 0.07069293409585953, -0.009620007127523422, 0.08509303629398346, -0.03399670869112015, 0.0340956412255764, -0.007073583081364632, 0.005173703655600548, -0.0003912077227141708, -0.056733060628175735, 0.05031898617744446, -0.06667764484882355, 0.022864412516355515, -0.0037170841824263334, 0.013620090670883656, 2.0784055206843026e-33, -0.02110682800412178, -0.027736008167266846, 0.10322994738817215, 0.10313385725021362, 0.010824855417013168, -0.0824817642569542, -0.019459741190075874, -0.1149907037615776, 0.025063689798116684, -0.014014308340847492, 0.04558337852358818, 0.10996580868959427, 0.09575044363737106, 0.07291878759860992, -0.03122738003730774, -0.025167906656861305, -0.07263850420713425, 0.06683363020420074, 0.01388951949775219, 0.08722826838493347, 0.02936425805091858, -0.027029773220419884, -0.008447273634374142, 0.023492082953453064, -0.04942672327160835, 0.04159210994839668, 0.054194435477256775, -0.022069843485951424, -0.05778251215815544, -0.003733414225280285, -0.055388085544109344, -0.047282345592975616, -0.07863232493400574, -0.1286429762840271, -0.026418710127472878, -0.0008015874191187322, 0.0026952296029776335, -0.032882459461688995, -0.04803996533155441, -0.04867405444383621, 0.005400035064667463, -0.02951948530972004, 0.06256400793790817, 0.04248971864581108, 0.03823879733681679, 0.024852504953742027, 0.0200659167021513, -0.08283347636461258, 0.005075175780802965, 0.06007709354162216, 0.02555796504020691, -0.059471726417541504, 0.0482001006603241, -0.026827039197087288, 0.022050101310014725, -0.0538971945643425, -0.0933409333229065, 0.07938168197870255, -0.011495156213641167, -0.0005620927549898624, 0.09660868346691132, -0.04670794680714607, -0.0404181107878685, -0.021353160962462425, -0.02849995531141758, 0.04901193454861641, 0.05699636787176132, -0.11477632075548172, -0.013368145562708378, 0.0044656796380877495, 0.014717509970068932, 0.07611285895109177, 0.0016864227363839746, 0.035137541592121124, -0.013344047591090202, -0.010424374602735043, -0.010196452029049397, 0.016931569203734398, -0.01672697253525257, -0.06775541603565216, 0.02639106474816799, 0.03512343019247055, -0.10572730749845505, 0.0247434563934803, 0.06163372844457626, -0.02201962098479271, -0.025878839194774628, -0.04634745046496391, -0.03216627985239029, -0.015645472332835197, -0.031074780970811844, 0.005204964429140091, 0.0109846331179142, 0.07747501879930496, -0.031286317855119705, -4.7852306886601846e-33, 0.018415426835417747, -0.011749397031962872, 0.01335780881345272, 0.04829193651676178, 0.08495748788118362, -0.06955438107252121, 0.04748572036623955, -0.0206594318151474, 0.07426413148641586, -0.07553621381521225, 0.040999021381139755, -0.013478877954185009, 0.0043240138329565525, 0.0029119914397597313, 0.0898175984621048, 0.04963173717260361, -0.026316121220588684, 0.007887247018516064, -0.04714100807905197, 0.016629334539175034, -0.003675054060295224, -0.004185894504189491, -0.0026521082036197186, 0.019438913092017174, -0.013673567213118076, 0.052774544805288315, 0.023459043353796005, 0.002522167284041643, 0.015717418864369392, -0.09379227459430695, -0.03405385836958885, 0.0667058601975441, 0.00040050799725577235, -0.04395872354507446, -0.07191158086061478, 0.04350657761096954, 0.008656452409923077, 0.011930137872695923, -0.05002284795045853, 0.05211252346634865, 0.053353726863861084, 0.009333403781056404, -0.04708729311823845, 0.024875449016690254, -0.05536763370037079, -0.022509034723043442, 0.0007959241047501564, -0.012098148465156555, -0.0915742814540863, 0.010343949310481548, 0.04977090284228325, -0.07002381980419159, -0.05850071832537651, -0.032915275543928146, -0.008171235211193562, 0.023325830698013306, -0.03305326774716377, -0.05740900710225105, -0.028405683115124702, -0.03515981510281563, 0.02695966511964798, 0.10363442450761795, -0.04708203300833702, 0.009267991408705711, 0.01620764285326004, 0.011554707773029804, -0.0192251019179821, 0.003957477398216724, -0.06347402185201645, 0.04376470670104027, -0.09089687466621399, -0.05338478460907936, -0.07071816921234131, -0.01851627603173256, 0.04777197539806366, -0.015253395773470402, 0.004475454334169626, 0.03845242038369179, -0.013991320505738258, 0.020931033417582512, -0.06077617034316063, -0.024474475532770157, -0.020046941936016083, 0.00952133722603321, -0.021061357110738754, 0.118501216173172, -0.03665434569120407, -0.01254847552627325, -0.012687759473919868, 0.022432146593928337, 0.024145010858774185, -0.02043568715453148, -0.006887211464345455, 0.009986395947635174, -0.05852387845516205, -4.38162004456899e-08, 0.015491225756704807, 0.021480007097125053, -0.00697627617046237, -0.032834358513355255, -0.052469175308942795, 0.06189141795039177, -0.0010205223225057125, 0.002475362503901124, 0.0757058635354042, 0.020455634221434593, 0.013957944698631763, 0.03753185644745827, 0.12929652631282806, 0.0034666818100959063, 0.02184949815273285, 0.03209318593144417, -0.01955498196184635, 0.11067245900630951, -0.0873575359582901, 0.020204966887831688, -0.02284649945795536, -0.06607277691364288, 0.003524709725752473, -0.002807579468935728, -0.06513551622629166, -0.08466306328773499, -0.04122040048241615, -0.030070004984736443, -0.03726770728826523, 0.0313153974711895, -0.005942262709140778, 0.03952706605195999, 0.023346995934844017, 0.027384981513023376, -0.03547452390193939, -0.07377496361732483, 0.06885901838541031, -0.043723396956920624, -0.08892566710710526, 0.05596079304814339, -0.0667925700545311, -0.03716839849948883, -0.005259085912257433, 0.0385635569691658, -0.09651007503271103, 0.0002507306635379791, -0.027411237359046936, -0.03202563524246216, 0.002824015449732542, -0.06954695284366608, 0.05992802977561951, 0.009186235256493092, 0.055766761302948, -0.005779403727501631, -0.09632430970668793, 0.12422192841768265, -0.03595492243766785, 0.027448482811450958, 0.009518544189631939, -0.003590002888813615, 0.036727018654346466, -0.08496488630771637, -0.04982610046863556, 0.048484258353710175], payload={'text': '# Choose Health:\\n Be Active\\n\\n\\n##### A physical activity guide for older Australians\\n\\n###### An initiative of the Australian Government in\\n\\n association with Sports Medicine Australia\\n\\n\\n-----\\n\\n**Choose Health: Be Active**\\n\\nFirst printed April 2005\\nRevised and reprinted April 2008\\nRevised and reprinted June 2008\\nISBN 978-1-920720-2856'})]\n"
     ]
    }
   ],
   "source": [
    "print(points[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising the Qdrant Client and Creating a Collection\n",
    "\n",
    "This section initialises a Qdrant client and creates a collection to store the text chunk embeddings with a specific configuration.\n",
    "\n",
    "- `client`: Initialises a Qdrant client using an in-memory database (`:memory:`), suitable for testing or temporary storage.\n",
    "- `COLLECTION_NAME`: Defines the name of the collection where the text embeddings will be stored.\n",
    "- `create_collection`: Creates a new collection in Qdrant with:\n",
    "  - `size=384`: The dimensionality of the vectors (matching the output size of the `all-MiniLM-L6-v2` model).\n",
    "  - `distance=Distance.COSINE`: Specifies the use of cosine similarity as the distance metric for comparing vectors.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "COLLECTION_NAME = 'my_text_chunks'\n",
    "\n",
    "# Create a collection with specific configuration\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading Data Points to Qdrant Collection\n",
    "\n",
    "This step uploads the prepared data points to the specified Qdrant collection.\n",
    "\n",
    "- `upsert`: Adds or updates the data points in the specified Qdrant collection.\n",
    "  - `collection_name`: The name of the collection where data points are stored (`my_text_chunks`).\n",
    "  - `wait=True`: Ensures the operation is completed before proceeding, providing immediate feedback on the upload status.\n",
    "  - `points`: The list of `PointStruct` objects containing the unique IDs, embeddings, and optional payloads to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    wait=True,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying Qdrant for Closest Matches\n",
    "\n",
    "This function queries the Qdrant vector database to find the top-k closest matches to a given query embedding.\n",
    "\n",
    "- Search Qdrant - Retrieves the top-k matches based on the query embedding.\n",
    "- Format Results - Returns a list of dictionaries containing the match ID, text, and similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_qdrant(query_embedding, collection_name, top_k=3):\n",
    "    \"\"\"\n",
    "    Queries the Qdrant vector database to retrieve the top-k closest matches\n",
    "    to a given embedding.\n",
    "\n",
    "    Args:\n",
    "        query_embedding (list): The vector embedding representing the query.\n",
    "        collection_name (str): The name of the Qdrant collection to search.\n",
    "        top_k (int, optional): The number of closest matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of payloads from the top-k closest matches found.\n",
    "    \"\"\"\n",
    "\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    # Format the results\n",
    "    formatted_results = [\n",
    "        {\n",
    "            \"id\": hit.id,\n",
    "            \"text\": hit.payload.get(\"text\", \"\"),\n",
    "            \"score\": hit.score\n",
    "        }\n",
    "        for hit in search_result\n",
    "    ]\n",
    "\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Searching and Reranking Vector Matches\n",
    "\n",
    "This example shows how to perform a search using Qdrant, display the initial results, and then rerank these results using a ranking model.\n",
    "\n",
    "1. Search for Initial Results: Encode the query and search Qdrant to find the closest matches.\n",
    "2. Display Initial Results: Print the top matches retrieved from Qdrant.\n",
    "3. Rerank Results: Use the `Ranker` model to reorder the initial results based on relevance.\n",
    "4. Display Reranked Results: Print the matches after reranking for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Results Before Re-ranking:\n",
      "\n",
      "ID: adb6738f-ae06-4870-91c0-3c530fc5b30f\n",
      "Text: ###### TAS Sport and Recreatio...\n",
      "Old Score: 0.668080747127533\n",
      "\n",
      "ID: a32c097c-2f48-4dd3-b30b-67086af3574a\n",
      "Text: -----\n",
      "\n",
      "### Useful Contacts\n",
      "\n",
      "##...\n",
      "Old Score: 0.48196303844451904\n",
      "\n",
      "ID: da2b37bc-f8f0-4ee2-9ecd-0ed4cace9bfe\n",
      "Text: This booklet was produced by t...\n",
      "Old Score: 0.47543221712112427\n",
      "\n",
      "ID: e83b6727-c040-47d3-b165-a47db5f356bb\n",
      "Text: # Choose Health:\n",
      " Be Active\n",
      "\n",
      "\n",
      "...\n",
      "Old Score: 0.4655294418334961\n",
      "\n",
      "\n",
      "Results After Re-ranking:\n",
      "\n",
      "ID: adb6738f-ae06-4870-91c0-3c530fc5b30f\n",
      "Text: ###### TAS Sport and Recreatio...\n",
      "New Score: 0.9982047080993652\n",
      "\n",
      "ID: a32c097c-2f48-4dd3-b30b-67086af3574a\n",
      "Text: -----\n",
      "\n",
      "### Useful Contacts\n",
      "\n",
      "##...\n",
      "New Score: 0.06663087755441666\n",
      "\n",
      "ID: da2b37bc-f8f0-4ee2-9ecd-0ed4cace9bfe\n",
      "Text: This booklet was produced by t...\n",
      "New Score: 0.0004697415861301124\n",
      "\n",
      "ID: e83b6727-c040-47d3-b165-a47db5f356bb\n",
      "Text: # Choose Health:\n",
      " Be Active\n",
      "\n",
      "\n",
      "...\n",
      "New Score: 0.0001939923531608656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for a vector before re-ranking\n",
    "QUERY_TEXT = \"Sport and Recreation Tasmania\"\n",
    "query_vector = encoder.encode([QUERY_TEXT])[0]  # Encode the search query\n",
    "\n",
    "# Initial search using Qdrant\n",
    "initial_results_test = query_qdrant(query_vector, COLLECTION_NAME, top_k=4)\n",
    "print(\"Initial Results Before Re-ranking:\\n\")\n",
    "for result in initial_results_test:\n",
    "    print(f\"ID: {result['id']}\\n\"\n",
    "          f\"Text: {result['text'][:30]}...\\n\"\n",
    "          f\"Old Score: {result.get('score', 'N/A')}\\n\")\n",
    "\n",
    "# Re-rank the initial results\n",
    "ranker = Ranker(model_name=\"ms-marco-MiniLM-L-12-v2\", cache_dir=\"/opt\")\n",
    "rerankrequest_test = RerankRequest(QUERY_TEXT, initial_results_test)\n",
    "results = ranker.rerank(rerankrequest_test)\n",
    "print(\"\\nResults After Re-ranking:\\n\")\n",
    "for result in results:\n",
    "    print(f\"ID: {result['id']}\\n\"\n",
    "          f\"Text: {result['text'][:30]}...\\n\"\n",
    "          f\"New Score: {result.get('score', 'N/A')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Environment Variables for API Access\n",
    "This step sets the environment variable needed to authenticate and access the Groq API.\n",
    "\n",
    "- `%env`: A Jupyter magic command used to set environment variables within the notebook.\n",
    "- `GROQ_API_KEY`: The environment variable that stores the API key required for authenticating requests to the Groq API.\n",
    "\n",
    "**Note:** Be cautious when sharing API keys to avoid unauthorised access!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GROQ_API_KEY="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising the ChatGroq Model\n",
    "\n",
    "This section initialises the `ChatGroq` model with streaming enabled, allowing real-time interaction with the model.\n",
    "\n",
    "- `chat_model`: An instance of the `ChatGroq` model initialised with:\n",
    "  - `model_name`: Specifies the model version to use (`llama-3.1-70b-versatile`).\n",
    "  - `api_key`: The API key retrieved from the environment variable (`GROQ_API_KEY`) for authentication.\n",
    "  - `streaming=True`: Enables streaming, allowing for real-time output as the model processes input, which is useful for interactive sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the ChatGroq model with streaming enabled\n",
    "chat_model = ChatGroq(\n",
    "    model_name='llama-3.1-8b-instant',\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"), streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Responses Using Context and Re-ranking\n",
    "\n",
    "This section demonstrates how to generate a response using the retrieved context and re-ranked search results.\n",
    "\n",
    "**Set-up:**\n",
    "\n",
    "1. Initialise Conversation Memory: Keeps track of the conversation history.\n",
    "2. Define the Chat Prompt Template: Formats the input for the chat model, combining context and the user's question\n",
    "\n",
    "The `generate_response` function handles user input, performs a search, reranks the results, and generates a response using the ChatGroq model.\n",
    "\n",
    "- Embedding Query: Converts user input into a query embedding.\n",
    "- Initial Search and Reranking: Retrieves and reranks search results to provide relevant context.\n",
    "- Context Extraction: Combines text from the top reranked results.\n",
    "- Response Generation: Uses the `ChatGroq` model to generate a response based on the provided context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Define the ChatPromptTemplate for user interaction\n",
    "TEMPLATE = \"\"\"Answer the following question from the context\n",
    "\n",
    "context = {context}\n",
    "\n",
    "question = {question}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], template=TEMPLATE\n",
    ")\n",
    "\n",
    "def generate_response(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response to a given user input by encoding the input,\n",
    "    performing a search, reranking results, and using the ChatGroq model\n",
    "    to generate a coherent response.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): The input provided by the user.\n",
    "        description (str): An optional description for the context or query.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response or an error message if an exception occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_embedding = encoder.encode([user_input])[0]\n",
    "        # Get initial search results\n",
    "        initial_results = query_qdrant(query_embedding, COLLECTION_NAME)\n",
    "        # Re-rank the results\n",
    "        rerankrequest = RerankRequest(user_input, initial_results)\n",
    "        reranked_results = ranker.rerank(rerankrequest)\n",
    "\n",
    "        # Extract the context from the reranked results\n",
    "        context = \"\\n\".join([result['text'] for result in reranked_results])\n",
    "\n",
    "        # Generate a response using ChatGroq model\n",
    "        full_response = chat_model.predict(\n",
    "            prompt_template.format(question=user_input, context=context)\n",
    "        )\n",
    "        return full_response.strip()\n",
    "    except (TypeError, KeyError) as te:\n",
    "        print(f\"TypeError or KeyError in generate_response: {str(te)}\")\n",
    "        return f\"Error: {str(te)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Usage\n",
    "\n",
    "This example demonstrates how to use the `generate_response` function to generate an answer based on a user's query.\n",
    "\n",
    "- `generate_response`: The function is called with the `USER_QUERY` to generate a response based on the available context and data.\n",
    "- `print(response)`: Outputs the generated response to the console for the user to see.\n",
    "\n",
    "This example shows how to use the function to interact with the chat model, retrieve relevant information, and produce an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.97it/s]\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phone number of Sport and Recreation Tasmania is 1800 252 476.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "USER_QUERY = \"What is the phone number of Sport and Recreation Tasmania?\"\n",
    "response = generate_response(USER_QUERY)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Question Without Context (For Comparison)\n",
    "\n",
    "This test directly queries the `ChatGroq` model with the user question without providing any additional contex as a point of comparison to our implementation of the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, I don't see the phone number of Sport and Recreation Tasmania in the provided context. I can suggest a possible solution for you. \n",
      "\n",
      "You can try contacting the Sport and Recreation Tasmania directly. You can look up their official website or social media channels to find their contact information, including their phone number.\n",
      "\n",
      "Alternatively, you can try searching online for the phone number of Sport and Recreation Tasmania. You can also try contacting the Tasmanian government's customer service number, which is 1300 65 64 63 (from within Tasmania), for assistance.\n"
     ]
    }
   ],
   "source": [
    "# Function to generate response without context\n",
    "def generate_response_without_context(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response from the chat model without using any context.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): The input string from the user for which a response\n",
    "                          is to be generated.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from the chat model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Directly use the chat model without any context\n",
    "        response_nc = chat_model.predict(\n",
    "            prompt_template.format(question=user_input, context=\"\")\n",
    "        )\n",
    "        return response_nc.strip()\n",
    "    except (TypeError, KeyError) as te:\n",
    "        print(f\"TypeError or KeyError in generate_response: {str(te)}\")\n",
    "        return f\"Error: {str(te)}\"\n",
    "\n",
    "# Example usage: Testing the question without any context\n",
    "USER_QUERY = \"What is the phone number of Sport and Recreation Tasmania?\"\n",
    "response_without_context = generate_response_without_context(USER_QUERY)\n",
    "print(response_without_context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
